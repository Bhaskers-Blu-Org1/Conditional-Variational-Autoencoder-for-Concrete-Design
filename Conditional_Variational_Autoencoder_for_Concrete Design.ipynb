{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import scale, StandardScaler, MinMaxScaler\n",
    "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error\n",
    "from math import sqrt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from matplotlib import rcParams\n",
    "\n",
    "from keras.layers import Input, Dense, Lambda, concatenate\n",
    "from keras.models import Model, load_model, Sequential, model_from_json\n",
    "from keras import backend as K\n",
    "from keras import metrics, optimizers, regularizers\n",
    "from keras.objectives import categorical_crossentropy, mean_squared_error\n",
    "from keras.callbacks import ModelCheckpoint, TensorBoard, EarlyStopping\n",
    "\n",
    "# fix random seed for reproducibility\n",
    "tf.set_random_seed(123)\n",
    "np.random.seed(123)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# load Concrete_Data.xls dataset, X: features, contains concrete mixes formula \n",
    "df_formula = pd.read_excel('Concrete_Data.xls')\n",
    "df_epd = pd.read_excel('environmental_impact.xlsx')\n",
    "X = df_formula.values[:,:7]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Samples separated into 6 groups <br>\n",
    "Group 0: < 3d <br>\n",
    "Group 1: 7d <br>\n",
    "Group 2: 14d <br>\n",
    "Group 3: 28d <br>\n",
    "Group 4: 56d <br>\n",
    "Group 5: > 90d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "day_to_idx = {1:0,\n",
    "              3:0,\n",
    "              7:1,\n",
    "             14:2,\n",
    "             28:3,\n",
    "             56:4,\n",
    "             90:5,\n",
    "             91:5,\n",
    "             100:5,\n",
    "             120:5,\n",
    "             180:5,\n",
    "             270:5,\n",
    "             360:5,\n",
    "             365:5}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert indices to one hot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "indices = []\n",
    "\n",
    "day_raw = df_formula.values[:,7]\n",
    "\n",
    "for i, day in enumerate(day_raw):\n",
    "    indices.append(day_to_idx[day])\n",
    "indices = np.array(indices)\n",
    "one_hot_vecs = np.zeros((day_raw.shape[0], 6)) \n",
    "one_hot_vecs[np.arange(day_raw.shape[0]), np.array(indices)] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get indices of samples from different groups, for later usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "group_0_train = np.where(indices == 0)[0]\n",
    "group_1_train = np.where(indices == 1)[0]\n",
    "group_2_train = np.where(indices == 2)[0]\n",
    "group_3_train = np.where(indices == 3)[0]\n",
    "group_4_train = np.where(indices == 4)[0]\n",
    "group_5_train = np.where(indices == 5)[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stack up group info, strength, and environmental impact"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Y = np.hstack((one_hot_vecs, df_formula.values[:,8].reshape(-1,1), df_epd.values[:,:12]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setup scaler for X and Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "scaler_X = MinMaxScaler().fit(X)\n",
    "scaler_Y = MinMaxScaler().fit(Y)\n",
    "X = scaler_X.transform(X)  \n",
    "Y = scaler_Y.transform(Y)\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define input tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_x = X.shape[1]\n",
    "n_y = Y.shape[1]\n",
    "n_z = 2\n",
    "\n",
    "# Q(z|X,y) -- encoder\n",
    "formula = Input(shape=(n_x,))\n",
    "cond = Input(shape=(n_y,))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialize encoder layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "inputs = concatenate([formula, cond])\n",
    "enc_hidden_1 = Dense(30, activation='relu')(inputs)\n",
    "enc_hidden_2 = Dense(25, activation='relu')(enc_hidden_1)\n",
    "z_mean = Dense(n_z)(enc_hidden_2)\n",
    "z_log_var = Dense(n_z)(enc_hidden_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define sampling function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sample_z(args):\n",
    "    z_mean, z_log_var = args\n",
    "    epsilon = K.random_normal(shape=(K.shape(z_mean)[0], n_z), mean=0., stddev=1.0)\n",
    "    return z_mean + K.exp(z_log_var / 2) * epsilon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Sample z ~ Q(z|X,y)\n",
    "z = Lambda(sample_z)([z_mean, z_log_var])\n",
    "z_cond = concatenate([z, cond])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# P(X|z,y) -- decoder\n",
    "dec_layer_1 = Dense(25, activation='relu') \n",
    "dec_layer_2 = Dense(30, activation='relu') \n",
    "dec_out = Dense(n_x, activation='sigmoid') #, activation='sigmoid'\n",
    "\n",
    "dec_hidden_1 = dec_layer_1(z_cond)\n",
    "dec_hidden_2 = dec_layer_2(dec_hidden_1)\n",
    "reconstructed = dec_out(dec_hidden_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# end-to-end autoencoder\n",
    "cvae = Model([formula, cond], reconstructed)\n",
    "\n",
    "# encoder, from inputs to latent space\n",
    "encoder = Model([formula, cond], z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "z_for_gen = Input(shape=(n_z,))\n",
    "z_cond_for_gen = concatenate([z_for_gen, cond])\n",
    "dec_hidden_1_for_gen = dec_layer_1(z_cond_for_gen)\n",
    "dec_hidden_2_for_gen = dec_layer_2(dec_hidden_1_for_gen)\n",
    "reconstructed_for_gen = dec_out(dec_hidden_2_for_gen)\n",
    "\n",
    "# generator, from latent space to reconstructed inputs\n",
    "generator = Model([z_for_gen, cond], reconstructed_for_gen)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def cvae_loss(feature, reconstructed):\n",
    "    reconstruction_loss = mean_squared_error(feature, reconstructed)\n",
    "    kl_loss = - 0.5 * K.mean(1 + z_log_var - K.square(z_mean) - K.exp(z_log_var), axis=-1)\n",
    "    return reconstruction_loss + kl_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compile model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_16 (InputLayer)           (None, 7)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_17 (InputLayer)           (None, 19)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_19 (Concatenate)    (None, 26)           0           input_16[0][0]                   \n",
      "                                                                 input_17[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_45 (Dense)                (None, 30)           810         concatenate_19[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dense_46 (Dense)                (None, 25)           775         dense_45[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_47 (Dense)                (None, 2)            52          dense_46[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_48 (Dense)                (None, 2)            52          dense_46[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lambda_7 (Lambda)               (None, 2)            0           dense_47[0][0]                   \n",
      "                                                                 dense_48[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_20 (Concatenate)    (None, 21)           0           lambda_7[0][0]                   \n",
      "                                                                 input_17[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_49 (Dense)                (None, 25)           550         concatenate_20[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dense_50 (Dense)                (None, 30)           780         dense_49[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_51 (Dense)                (None, 7)            217         dense_50[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 3,236\n",
      "Trainable params: 3,236\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "adam = optimizers.Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-08)\n",
    "cvae.compile(optimizer=adam, loss=cvae_loss)\n",
    "cvae.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_epoch = 100\n",
    "n_batch = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 824 samples, validate on 206 samples\n",
      "Epoch 1/100\n",
      "824/824 [==============================] - 2s 2ms/step - loss: 0.0751 - val_loss: 0.0508\n",
      "Epoch 2/100\n",
      "824/824 [==============================] - 0s 322us/step - loss: 0.0505 - val_loss: 0.0451\n",
      "Epoch 3/100\n",
      "824/824 [==============================] - 0s 544us/step - loss: 0.0457 - val_loss: 0.0417\n",
      "Epoch 4/100\n",
      "824/824 [==============================] - 0s 523us/step - loss: 0.0423 - val_loss: 0.0384\n",
      "Epoch 5/100\n",
      "824/824 [==============================] - 0s 346us/step - loss: 0.0398 - val_loss: 0.0366\n",
      "Epoch 6/100\n",
      "824/824 [==============================] - 0s 445us/step - loss: 0.0375 - val_loss: 0.0344\n",
      "Epoch 7/100\n",
      "824/824 [==============================] - 0s 278us/step - loss: 0.0358 - val_loss: 0.0321\n",
      "Epoch 8/100\n",
      "824/824 [==============================] - 0s 491us/step - loss: 0.0333 - val_loss: 0.0298\n",
      "Epoch 9/100\n",
      "824/824 [==============================] - 0s 479us/step - loss: 0.0319 - val_loss: 0.0286\n",
      "Epoch 10/100\n",
      "824/824 [==============================] - 1s 613us/step - loss: 0.0302 - val_loss: 0.0265\n",
      "Epoch 11/100\n",
      "824/824 [==============================] - 0s 391us/step - loss: 0.0289 - val_loss: 0.0254\n",
      "Epoch 12/100\n",
      "824/824 [==============================] - 0s 513us/step - loss: 0.0278 - val_loss: 0.0243\n",
      "Epoch 13/100\n",
      "824/824 [==============================] - 0s 347us/step - loss: 0.0272 - val_loss: 0.0238\n",
      "Epoch 14/100\n",
      "824/824 [==============================] - 0s 372us/step - loss: 0.0262 - val_loss: 0.0232\n",
      "Epoch 15/100\n",
      "824/824 [==============================] - 0s 502us/step - loss: 0.0255 - val_loss: 0.0225\n",
      "Epoch 16/100\n",
      "824/824 [==============================] - 0s 389us/step - loss: 0.0248 - val_loss: 0.0215\n",
      "Epoch 17/100\n",
      "824/824 [==============================] - 0s 342us/step - loss: 0.0241 - val_loss: 0.0211\n",
      "Epoch 18/100\n",
      "824/824 [==============================] - 0s 480us/step - loss: 0.0236 - val_loss: 0.0205\n",
      "Epoch 19/100\n",
      "824/824 [==============================] - 0s 323us/step - loss: 0.0231 - val_loss: 0.0200\n",
      "Epoch 20/100\n",
      "824/824 [==============================] - 0s 422us/step - loss: 0.0225 - val_loss: 0.0195\n",
      "Epoch 21/100\n",
      "824/824 [==============================] - 0s 494us/step - loss: 0.0220 - val_loss: 0.0191\n",
      "Epoch 22/100\n",
      "824/824 [==============================] - 0s 321us/step - loss: 0.0218 - val_loss: 0.0188\n",
      "Epoch 23/100\n",
      "824/824 [==============================] - 0s 330us/step - loss: 0.0213 - val_loss: 0.0190\n",
      "Epoch 24/100\n",
      "824/824 [==============================] - 0s 426us/step - loss: 0.0210 - val_loss: 0.0180\n",
      "Epoch 25/100\n",
      "824/824 [==============================] - 0s 346us/step - loss: 0.0204 - val_loss: 0.0179\n",
      "Epoch 26/100\n",
      "824/824 [==============================] - 0s 331us/step - loss: 0.0203 - val_loss: 0.0180\n",
      "Epoch 27/100\n",
      "824/824 [==============================] - 0s 443us/step - loss: 0.0201 - val_loss: 0.0174\n",
      "Epoch 28/100\n",
      "824/824 [==============================] - 0s 317us/step - loss: 0.0200 - val_loss: 0.0177\n",
      "Epoch 29/100\n",
      "824/824 [==============================] - 0s 308us/step - loss: 0.0197 - val_loss: 0.0173\n",
      "Epoch 30/100\n",
      "824/824 [==============================] - 0s 326us/step - loss: 0.0195 - val_loss: 0.0169\n",
      "Epoch 31/100\n",
      "824/824 [==============================] - 0s 448us/step - loss: 0.0192 - val_loss: 0.0166\n",
      "Epoch 32/100\n",
      "824/824 [==============================] - 0s 326us/step - loss: 0.0191 - val_loss: 0.0165\n",
      "Epoch 33/100\n",
      "824/824 [==============================] - 0s 322us/step - loss: 0.0189 - val_loss: 0.0164\n",
      "Epoch 34/100\n",
      "824/824 [==============================] - 0s 417us/step - loss: 0.0186 - val_loss: 0.0164\n",
      "Epoch 35/100\n",
      "824/824 [==============================] - 0s 335us/step - loss: 0.0186 - val_loss: 0.0161\n",
      "Epoch 36/100\n",
      "824/824 [==============================] - 0s 324us/step - loss: 0.0184 - val_loss: 0.0159\n",
      "Epoch 37/100\n",
      "824/824 [==============================] - 0s 480us/step - loss: 0.0183 - val_loss: 0.0160\n",
      "Epoch 38/100\n",
      "824/824 [==============================] - 0s 328us/step - loss: 0.0183 - val_loss: 0.0159\n",
      "Epoch 39/100\n",
      "824/824 [==============================] - 0s 309us/step - loss: 0.0181 - val_loss: 0.0155\n",
      "Epoch 40/100\n",
      "824/824 [==============================] - 0s 331us/step - loss: 0.0179 - val_loss: 0.0156\n",
      "Epoch 41/100\n",
      "824/824 [==============================] - 0s 423us/step - loss: 0.0177 - val_loss: 0.0160\n",
      "Epoch 42/100\n",
      "824/824 [==============================] - 0s 324us/step - loss: 0.0179 - val_loss: 0.0153\n",
      "Epoch 43/100\n",
      "824/824 [==============================] - 0s 312us/step - loss: 0.0176 - val_loss: 0.0155\n",
      "Epoch 44/100\n",
      "824/824 [==============================] - 0s 431us/step - loss: 0.0176 - val_loss: 0.0148\n",
      "Epoch 45/100\n",
      "824/824 [==============================] - 0s 330us/step - loss: 0.0176 - val_loss: 0.0151\n",
      "Epoch 46/100\n",
      "824/824 [==============================] - 0s 320us/step - loss: 0.0173 - val_loss: 0.0150\n",
      "Epoch 47/100\n",
      "824/824 [==============================] - 0s 383us/step - loss: 0.0176 - val_loss: 0.0153\n",
      "Epoch 48/100\n",
      "824/824 [==============================] - 0s 385us/step - loss: 0.0171 - val_loss: 0.0146\n",
      "Epoch 49/100\n",
      "824/824 [==============================] - 0s 318us/step - loss: 0.0171 - val_loss: 0.0152\n",
      "Epoch 50/100\n",
      "824/824 [==============================] - 0s 349us/step - loss: 0.0170 - val_loss: 0.0148\n",
      "Epoch 51/100\n",
      "824/824 [==============================] - 0s 441us/step - loss: 0.0171 - val_loss: 0.0151\n",
      "Epoch 52/100\n",
      "824/824 [==============================] - 0s 324us/step - loss: 0.0172 - val_loss: 0.0145\n",
      "Epoch 53/100\n",
      "824/824 [==============================] - 0s 317us/step - loss: 0.0171 - val_loss: 0.0147\n",
      "Epoch 54/100\n",
      "824/824 [==============================] - 0s 449us/step - loss: 0.0170 - val_loss: 0.0146\n",
      "Epoch 55/100\n",
      "824/824 [==============================] - 0s 322us/step - loss: 0.0172 - val_loss: 0.0144\n",
      "Epoch 56/100\n",
      "824/824 [==============================] - 0s 315us/step - loss: 0.0167 - val_loss: 0.0146\n",
      "Epoch 57/100\n",
      "824/824 [==============================] - 0s 322us/step - loss: 0.0169 - val_loss: 0.0144\n",
      "Epoch 58/100\n",
      "824/824 [==============================] - 0s 410us/step - loss: 0.0168 - val_loss: 0.0144\n",
      "Epoch 59/100\n",
      "824/824 [==============================] - 0s 304us/step - loss: 0.0168 - val_loss: 0.0144\n",
      "Epoch 60/100\n",
      "824/824 [==============================] - 0s 313us/step - loss: 0.0165 - val_loss: 0.0141\n",
      "Epoch 61/100\n",
      "824/824 [==============================] - 0s 543us/step - loss: 0.0165 - val_loss: 0.0146\n",
      "Epoch 62/100\n",
      "824/824 [==============================] - 0s 369us/step - loss: 0.0164 - val_loss: 0.0143\n",
      "Epoch 63/100\n",
      "824/824 [==============================] - 0s 320us/step - loss: 0.0164 - val_loss: 0.0138\n",
      "Epoch 64/100\n",
      "824/824 [==============================] - 0s 371us/step - loss: 0.0164 - val_loss: 0.0140\n",
      "Epoch 65/100\n",
      "824/824 [==============================] - 0s 312us/step - loss: 0.0163 - val_loss: 0.0139\n",
      "Epoch 66/100\n",
      "824/824 [==============================] - 0s 336us/step - loss: 0.0162 - val_loss: 0.0142\n",
      "Epoch 67/100\n",
      "824/824 [==============================] - 0s 473us/step - loss: 0.0160 - val_loss: 0.0138\n",
      "Epoch 68/100\n",
      "824/824 [==============================] - 0s 331us/step - loss: 0.0160 - val_loss: 0.0141\n"
     ]
    }
   ],
   "source": [
    "checkpointer = ModelCheckpoint(filepath = \"model_autoencoder.h5\",\n",
    "                               verbose = 0,\n",
    "                               save_best_only = True)\n",
    "\n",
    "tensorboard = TensorBoard(log_dir = './logs',\n",
    "                          histogram_freq = 0,\n",
    "                          write_graph = True,\n",
    "                          write_images = True)\n",
    "\n",
    "history = cvae.fit([X_train, Y_train], X_train,\n",
    "                epochs=n_epoch,\n",
    "                batch_size=n_batch,\n",
    "                shuffle=True,\n",
    "                callbacks = [EarlyStopping(patience = 5)],\n",
    "                validation_data=([X_test, Y_test], X_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate new samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "num_of_samples = 60000\n",
    "day_vecs = np.zeros((num_of_samples, 6))\n",
    "day_idx = np.random.choice(6, num_of_samples)\n",
    "group_0 = np.where(day_idx == 0)[0]\n",
    "group_1 = np.where(day_idx == 1)[0]\n",
    "group_2 = np.where(day_idx == 2)[0]\n",
    "group_3 = np.where(day_idx == 3)[0]\n",
    "group_4 = np.where(day_idx == 4)[0]\n",
    "group_5 = np.where(day_idx == 5)[0]\n",
    "day_vecs = np.zeros((num_of_samples, 6))\n",
    "day_vecs[np.arange(num_of_samples), day_idx] = 1\n",
    "np.random.seed(1)\n",
    "strength_and_environmental = np.random.uniform(0, 1, (num_of_samples, 13))\n",
    "mean = [0,0]\n",
    "cov = [[1, 0], [0, 1]]\n",
    "np.random.seed(1)\n",
    "Z_sampling = np.random.multivariate_normal(mean, cov, num_of_samples)\n",
    "Y_sampling = np.hstack((day_vecs, strength_and_environmental))\n",
    "samples_scaled = generator.predict([Z_sampling, Y_sampling])\n",
    "generated_samples = scaler_X.inverse_transform(samples_scaled)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:python3.5]",
   "language": "python",
   "name": "conda-env-python3.5-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
